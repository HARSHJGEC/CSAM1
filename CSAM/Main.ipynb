{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense,Conv2D,MaxPooling2D,Flatten,BatchNormalization,Dropout,AveragePooling2D,Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class inception(keras.Model):\n",
    "    def __init__(self,num_first_filter,num_second_filter):\n",
    "        super().__init__()\n",
    "        self.conv1=Conv2D(num_first_filter,kernel_size=(1,1),strides=1,padding='valid',activation='relu')\n",
    "        self.bn1=BatchNormalization()\n",
    "        self.conv2A=Conv2D(num_second_filter,kernel_size=(1,1),strides=1,padding='valid',activation='relu')\n",
    "        self.bn2A=BatchNormalization()\n",
    "        self.conv2B=Conv2D(num_second_filter,kernel_size=(3,3),strides=1,padding='same',activation='relu')\n",
    "        self.bn2B=BatchNormalization()\n",
    "        self.conv2C=Conv2D(num_second_filter,kernel_size=(3,3),strides=1,padding='same',activation='relu')\n",
    "        self.bn2C=BatchNormalization()\n",
    "        self.pool=MaxPooling2D(pool_size=2, strides=1, padding='same')\n",
    "    def call(self,inputs):\n",
    "        x=self.bn2B(self.conv2B(self.bn1(self.conv1(inputs))))\n",
    "        # print(x.shape)\n",
    "        x1=self.bn2C(self.conv2C(x))\n",
    "        # print(x1.shape)\n",
    "        x2=self.bn2A(self.conv2A(self.pool(inputs)))\n",
    "        x3=self.bn2A(self.conv2A(inputs))\n",
    "        \n",
    "        output=tf.concat([x,x1,x2,x3],-1)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class inception_reduction(keras.Model):\n",
    "    def __init__(self,num_first_filter,num_second_filter,num_third_filter):\n",
    "        super(inception_reduction,self).__init__()\n",
    "        self.conv1=Conv2D(num_first_filter,kernel_size=(1,1),strides=1,padding='valid',activation='relu')\n",
    "        self.bn1=BatchNormalization()\n",
    "        self.conv1A=Conv2D(num_first_filter,kernel_size=(3,3),strides=1,padding='same',activation='relu')\n",
    "        self.bn1A=BatchNormalization()\n",
    "        self.conv2A=Conv2D(num_second_filter,kernel_size=(3,3),strides=2,padding='same',activation='relu')\n",
    "        self.bn2A=BatchNormalization()\n",
    "        self.conv2B=Conv2D(num_second_filter,kernel_size=(3,3),strides=2,padding='same',activation='relu')\n",
    "        self.bn2B=BatchNormalization()\n",
    "        self.pool=MaxPooling2D(pool_size=2, strides=2)\n",
    "        self.conv3=Conv2D(num_third_filter,kernel_size=(1,1),strides=1,padding='valid',activation='relu')\n",
    "        self.bn3=BatchNormalization()\n",
    "    def call(self,inputs):\n",
    "        # x=self.conv64(inputs)\n",
    "        x=self.bn1A(self.conv1A(self.bn1(self.conv1(inputs))))\n",
    "        # print(x.shape)\n",
    "        x=self.bn2A(self.conv2A(x))\n",
    "        # print(x.shape)\n",
    "        x1=self.bn2B(self.conv2B(self.bn1(self.conv1(inputs))))\n",
    "        x2=self.bn3(self.conv3(self.pool(inputs)))\n",
    "        output=tf.concat([x,x1,x2],-1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class relu(keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    def call(self,inputs,num_filter):\n",
    "        output=Conv2D(num_filter,kernel_size=(1,1),strides=1,padding='valid',activation='relu')(inputs)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class inception_resnet(keras.Model):\n",
    "    def __init__(self,num_first_filter,num_second_filter):\n",
    "        super(inception_resnet,self).__init__()\n",
    "        self.conv1=Conv2D(num_first_filter,kernel_size=(1,1),strides=1,padding='valid',activation='relu')\n",
    "        self.bn1=BatchNormalization()\n",
    "        self.conv2=Conv2D(num_second_filter,kernel_size=(1,1),strides=1,padding='valid',activation='relu')\n",
    "        self.bn2=BatchNormalization()\n",
    "        self.conv1A=Conv2D(num_first_filter,kernel_size=(3,3),strides=1,padding='same',activation='relu')\n",
    "        self.bn1A=BatchNormalization()\n",
    "        self.conv2A=Conv2D(num_second_filter,kernel_size=(3,3),strides=1,padding='same',activation='relu')\n",
    "        self.bn2A=BatchNormalization()\n",
    "        self.conv2B=Conv2D(num_second_filter,kernel_size=(3,3),strides=1,padding='same',activation='relu')\n",
    "        self.bn2B=BatchNormalization()\n",
    "        self.relu=relu()\n",
    "    def call(self,inputs):\n",
    "        x=self.conv1A(self.bn1(self.conv1(inputs)))\n",
    "        x=self.bn1A(x)\n",
    "        # print(x.shape)\n",
    "        x=self.bn2A(self.conv2A(x))\n",
    "        # print(x.shape)\n",
    "        x1=self.bn2B(self.conv2B(self.bn1(self.conv1(inputs))))\n",
    "        # print(x1.shape)\n",
    "        x2=self.bn2(self.conv2(inputs))\n",
    "        # print(x2.shape)\n",
    "        output=tf.concat([x,x1,x2],-1)\n",
    "        num_filter=output.shape[-1]\n",
    "        output=self.relu(output+inputs,num_filter)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class inception_resnet_V2(keras.Model):\n",
    "    def __init__(self,num_first_filter,num_second_filter,num_third_filter):\n",
    "        super(inception_resnet_V2,self).__init__()\n",
    "        self.conv1=Conv2D(num_first_filter,kernel_size=(1,1),strides=1,padding='valid',activation='relu')\n",
    "        self.bn1=BatchNormalization()\n",
    "        self.conv3=Conv2D(num_third_filter,kernel_size=(1,1),strides=1,padding='valid',activation='relu')\n",
    "        self.bn3=BatchNormalization()\n",
    "        self.conv2=Conv2D(num_second_filter,kernel_size=(3,3),strides=1,padding='same',activation='relu')\n",
    "        self.bn2=BatchNormalization()\n",
    "        self.conv3A=Conv2D(num_third_filter,kernel_size=(3,3),strides=1,padding='same',activation='relu')\n",
    "        self.bn3A=BatchNormalization()\n",
    "        self.conv3B=Conv2D(num_third_filter,kernel_size=(3,3),strides=1,padding='same',activation='relu')\n",
    "        self.bn3B=BatchNormalization()\n",
    "        self.pool=MaxPooling2D(pool_size=2, strides=1,padding='same')\n",
    "        self.relu=relu()\n",
    "        self.conv3C=Conv2D(num_third_filter,kernel_size=(1,1),strides=1,padding='same',activation='relu')\n",
    "        self.bn3C=BatchNormalization()\n",
    "    def call(self,inputs):\n",
    "        x=self.conv2(self.bn1(self.conv1(inputs)))\n",
    "        x=self.bn2(x)\n",
    "        # print(x.shape)\n",
    "        x=self.bn3A(self.conv3A(x))\n",
    "        # print(x.shape)\n",
    "        x1=self.bn3B(self.conv3B(self.bn1(self.conv1(inputs))))\n",
    "        # print(x1.shape)\n",
    "        x2=self.bn3(self.conv3(inputs))\n",
    "        # print(x2.shape)\n",
    "        x3=self.bn3C(self.conv3C(self.pool(inputs)))\n",
    "        output=tf.concat([x,x1,x2,x3],-1)\n",
    "        num_filter=output.shape[-1]\n",
    "        output=self.relu(output+inputs,num_filter)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"inception_resnet_v2_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_7 (Conv2D)           multiple                  68208     \n",
      "                                                                 \n",
      " batch_normalization_6 (Bat  multiple                  448       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           multiple                  92568     \n",
      "                                                                 \n",
      " batch_normalization_7 (Bat  multiple                  608       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           multiple                  129152    \n",
      "                                                                 \n",
      " batch_normalization_8 (Bat  multiple                  512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          multiple                  175256    \n",
      "                                                                 \n",
      " batch_normalization_9 (Bat  multiple                  608       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          multiple                  153368    \n",
      "                                                                 \n",
      " batch_normalization_10 (Ba  multiple                  608       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  multiple                  0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " relu_1 (relu)               multiple                  0         \n",
      "                                                                 \n",
      " conv2d_12 (Conv2D)          multiple                  92568     \n",
      "                                                                 \n",
      " batch_normalization_11 (Ba  multiple                  608       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 714512 (2.73 MB)\n",
      "Trainable params: 712816 (2.72 MB)\n",
      "Non-trainable params: 1696 (6.62 KB)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TensorShape([32, 14, 14, 608])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = inception_resnet_V2(112,128,152)\n",
    "# model = inception_reduction(96,112,384)\n",
    "# model = inception(48,64)\n",
    "# Sample input with a definite batch size of 32\n",
    "sample_input = tf.random.normal((32, 14,14,608))\n",
    "output = model(sample_input)\n",
    "\n",
    "model.summary()\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(keras.Model):\n",
    "    def __init__(self):\n",
    "        super(Attention,self).__init__()\n",
    "        self.conv1=Conv2D(1024,kernel_size=(1,1),strides=1,padding='valid',activation='relu')\n",
    "        self.bn1=BatchNormalization()\n",
    "        self.softmax=Softmax(axis=-1)\n",
    "    def call(self,input1,input2):\n",
    "        f=self.bn1(self.conv1(input1))\n",
    "        G=tf.multiply(f,input2)\n",
    "        p=self.softmax(G)\n",
    "        temp=tf.multiply(p,f)\n",
    "        attn=tf.reduce_sum(temp,axis=[1,2])\n",
    "        return attn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"attention\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_14 (Conv2D)          multiple                  394240    \n",
      "                                                                 \n",
      " batch_normalization_12 (Ba  multiple                  4096      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " softmax (Softmax)           multiple                  0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 398336 (1.52 MB)\n",
      "Trainable params: 396288 (1.51 MB)\n",
      "Non-trainable params: 2048 (8.00 KB)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TensorShape([32, 1024])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input1 = tf.random.normal(shape=(32, 28, 28, 384))\n",
    "input2 = tf.random.normal(shape=(32, 1, 1, 1024))\n",
    "model = Attention()\n",
    "output = model(input1,input2)\n",
    "\n",
    "model.summary()\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neural_Network(keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1=Conv2D(32,kernel_size=(3,3),strides=2,padding='valid',activation='relu')\n",
    "        self.bn1=BatchNormalization()\n",
    "        self.conv2=Conv2D(64,kernel_size=(3,3),strides=1,padding='same',activation='relu')\n",
    "        self.bn2=BatchNormalization()\n",
    "        self.pool3=MaxPooling2D(pool_size=2, strides=2, padding='valid')\n",
    "        self.inception4=inception(48,64)\n",
    "        self.inception5=inception(48,64)\n",
    "        self.inception_red6=inception_reduction(64,96,192)\n",
    "        self.inception_red10=inception_reduction(96,112,384)\n",
    "        self.relu=relu()\n",
    "        self.inception_resnet7=inception_resnet(96,128)\n",
    "        self.inception_resnet8=inception_resnet(96,128)\n",
    "        self.inception_resnet11=inception_resnet_V2(112,128,152)\n",
    "        self.inception_resnet12=inception_resnet_V2(112,128,152)\n",
    "        self.inception_red14=inception_reduction(112,128,608)\n",
    "        self.conv15=Conv2D(1024,kernel_size=(3,3),strides=1,padding='same',activation='relu')\n",
    "        self.bn15=BatchNormalization()\n",
    "        self.pool16=AveragePooling2D(pool_size=(7,7))\n",
    "        self.attention1=Attention()\n",
    "        self.attention2=Attention()\n",
    "        self.ffn18=Dense(512, activation='relu')\n",
    "        self.bn18=BatchNormalization()\n",
    "        # self.ffn19=Dense(2, activation='relu')\n",
    "        # self.softmax19=Softmax()\n",
    "    def call(self,inputs):\n",
    "        x_1=self.bn1(self.conv1(inputs))\n",
    "        print(x_1.shape)\n",
    "        x_2=self.bn2(self.conv2(x_1))\n",
    "        print(x_2.shape)\n",
    "        x_3=self.pool3(x_2)\n",
    "        print(x_3.shape)\n",
    "        x_4=self.inception4(x_3)\n",
    "        x_5=self.inception5(x_4)\n",
    "        x_6=self.inception_red6(x_5)\n",
    "        num_filter=x_6.shape[-1]\n",
    "        x_6=self.relu(x_6,num_filter)\n",
    "        print(x_6.shape)\n",
    "        x_7=self.inception_resnet7(x_6)\n",
    "        print(x_7.shape)\n",
    "        x_8=self.inception_resnet8(x_7)\n",
    "        x_10=self.inception_red10(x_8)\n",
    "        x_11=self.inception_resnet11(x_10)\n",
    "        x_12=self.inception_resnet12(x_11)\n",
    "        x_14=self.inception_red14(x_12)\n",
    "        x_15=self.bn15(self.conv15(x_14))\n",
    "        x_16=self.pool16(x_15)\n",
    "        x_9=self.attention1(x_8,x_16)\n",
    "        x_13=self.attention2(x_12,x_16)\n",
    "        x_17=tf.concat([x_9,x_13],-1)\n",
    "        x_18=self.bn18(self.ffn18(x_17))\n",
    "        # x_19=self.ffn19(x_18)\n",
    "        # logits_softmax, logits_centers = tf.split(x_19, [2, 2], axis=-1)\n",
    "        # print(logits_centers.shape)\n",
    "        # output=self.softmax19(x_19)\n",
    "        output=x_18\n",
    "        print(f'output{output.shape}')\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 112, 112, 32)\n",
      "(32, 112, 112, 64)\n",
      "(32, 56, 56, 64)\n",
      "(32, 28, 28, 384)\n",
      "(32, 28, 28, 384)\n",
      "output(32, 512)\n",
      "Model: \"neural__network_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_564 (Conv2D)         multiple                  896       \n",
      "                                                                 \n",
      " batch_normalization_519 (B  multiple                  128       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " conv2d_565 (Conv2D)         multiple                  18496     \n",
      "                                                                 \n",
      " batch_normalization_520 (B  multiple                  256       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " max_pooling2d_82 (MaxPooli  multiple                  0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " inception_20 (inception)    multiple                  72880     \n",
      "                                                                 \n",
      " inception_21 (inception)    multiple                  94384     \n",
      "                                                                 \n",
      " inception_reduction_30 (in  multiple                  215552    \n",
      " ception_reduction)                                              \n",
      "                                                                 \n",
      " inception_reduction_31 (in  multiple                  464800    \n",
      " ception_reduction)                                              \n",
      "                                                                 \n",
      " relu_52 (relu)              multiple                  0         \n",
      "                                                                 \n",
      " inception_resnet_20 (incep  multiple                  393024    \n",
      " tion_resnet)                                                    \n",
      "                                                                 \n",
      " inception_resnet_21 (incep  multiple                  393024    \n",
      " tion_resnet)                                                    \n",
      "                                                                 \n",
      " inception_resnet_v2_22 (in  multiple                  714512    \n",
      " ception_resnet_V2)                                              \n",
      "                                                                 \n",
      " inception_resnet_v2_23 (in  multiple                  714512    \n",
      " ception_resnet_V2)                                              \n",
      "                                                                 \n",
      " inception_reduction_32 (in  multiple                  814144    \n",
      " ception_reduction)                                              \n",
      "                                                                 \n",
      " conv2d_611 (Conv2D)         multiple                  7963648   \n",
      "                                                                 \n",
      " batch_normalization_566 (B  multiple                  4096      \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " average_pooling2d_10 (Aver  multiple                  0         \n",
      " agePooling2D)                                                   \n",
      "                                                                 \n",
      " attention_20 (Attention)    multiple                  398336    \n",
      "                                                                 \n",
      " attention_21 (Attention)    multiple                  627712    \n",
      "                                                                 \n",
      " dense_12 (Dense)            multiple                  1049088   \n",
      "                                                                 \n",
      " batch_normalization_569 (B  multiple                  2048      \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13941536 (53.18 MB)\n",
      "Trainable params: 13922720 (53.11 MB)\n",
      "Non-trainable params: 18816 (73.50 KB)\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TensorShape([32, 512])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Neural_Network()\n",
    "\n",
    "# Sample input with a definite batch size of 32\n",
    "sample_input = tf.random.normal((32, 225, 225, 3))\n",
    "output = model(sample_input)\n",
    "\n",
    "print(model.summary())\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decision_Network(keras.Model):\n",
    "    def __init__(self,num_classes,output_dim):\n",
    "        super().__init__()\n",
    "        self.conv1=Dense(2, activation='relu')\n",
    "        self.conv2=Dense(2, activation='relu')\n",
    "        self.softmax=Softmax()\n",
    "        self.NN1=Neural_Network()\n",
    "        self.centers = tf.Variable(tf.random.normal((num_classes, output_dim)), trainable=True)\n",
    "    def call(self,inputs):\n",
    "        x=self.conv1(self.NN1(inputs))\n",
    "        softmax=self.softmax(x)\n",
    "        center=self.conv2(self.NN1(inputs))\n",
    "        output=softmax+center\n",
    "        return output\n",
    "    def center_loss(self, features):\n",
    "    \n",
    "        squared_distances = tf.reduce_sum(tf.square(features - self.centers), axis=1, keepdims=True)\n",
    "\n",
    "        batch_size = tf.shape(features)[0]\n",
    "        labels = tf.expand_dims(tf.range(batch_size), axis=1)  # Assuming integer class labels\n",
    "        mask = tf.cast(tf.equal(labels, tf.transpose(tf.range(self.centers.shape[0]))), dtype=tf.float32)\n",
    "        masked_distances = squared_distances * mask\n",
    "\n",
    "        epsilon = 1e-6\n",
    "        average_loss = tf.reduce_sum(masked_distances) / (batch_size * self.centers.shape[0] + epsilon)\n",
    "        return average_loss\n",
    "\n",
    "    def compile(self, optimizer, loss_weights=None):\n",
    "        \"\"\"\n",
    "        Compiles the model with a combined loss function including softmax and center loss.\n",
    "\n",
    "        Args:\n",
    "        optimizer: The optimizer to use for training.\n",
    "        loss_weights: Optional dictionary specifying weights for different loss components.\n",
    "        \"\"\"\n",
    "        def combined_loss(y_true, y_pred):\n",
    "        # Assuming categorical crossentropy for softmax loss\n",
    "            softmax_loss = tf.keras.losses.categorical_crossentropy(y_true, y_pred)\n",
    "            center_loss = self.center_loss(self.NN1(y_true))  # Features from NN1 for center loss\n",
    "            if loss_weights is None:\n",
    "                loss_weights = {\"softmax_loss\": 1.0, \"center_loss\": 0.006}  # Example weights\n",
    "            total_loss = loss_weights[\"softmax_loss\"] * softmax_loss + loss_weights[\"center_loss\"] * center_loss\n",
    "            return total_loss\n",
    "\n",
    "        super().compile(optimizer=optimizer, loss=combined_loss)\n",
    "\n",
    "# Example usage\n",
    "model = Decision_Network(num_classes=2,output_dim=2)  # Replace 10 with actual number of classes\n",
    "model.compile(optimizer='SGD')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 112, 112, 32)\n",
      "(32, 112, 112, 64)\n",
      "(32, 56, 56, 64)\n",
      "(32, 28, 28, 384)\n",
      "(32, 28, 28, 384)\n",
      "output(32, 512)\n",
      "(32, 112, 112, 32)\n",
      "(32, 112, 112, 64)\n",
      "(32, 56, 56, 64)\n",
      "(32, 28, 28, 384)\n",
      "(32, 28, 28, 384)\n",
      "output(32, 512)\n",
      "Model: \"decision__network_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_22 (Dense)            multiple                  1026      \n",
      "                                                                 \n",
      " dense_23 (Dense)            multiple                  1026      \n",
      "                                                                 \n",
      " softmax_35 (Softmax)        multiple                  0         \n",
      "                                                                 \n",
      " neural__network_14 (Neural  multiple                  13941536  \n",
      " _Network)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13943592 (53.19 MB)\n",
      "Trainable params: 13924776 (53.12 MB)\n",
      "Non-trainable params: 18816 (73.50 KB)\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "sample_input = tf.random.normal((32, 225, 225, 3))\n",
    "output = model(sample_input)\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([32, 2])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
